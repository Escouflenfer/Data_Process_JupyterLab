{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac39c21d-db36-4274-b3e5-6f58fe5ccfcb",
   "metadata": {},
   "source": [
    "## **Jupyter Notebook for exporting data into an HDF5 file. Only **\n",
    "- version: XRD-release-1.4 <br>\n",
    "- author: William Rigaut <br>\n",
    "- date: 5.06.2024  <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9061a858-ee7f-4c6a-9621-7800327611fa",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import h5py;\n",
    "import os;\n",
    "import re;\n",
    "import xml.etree.ElementTree as ET;\n",
    "import numpy as np;\n",
    "from tqdm.notebook import tqdm;\n",
    "\n",
    "def is_excluded(line):\n",
    "    excluded = ['RAS', 'DISP', 'FILE', 'MEAS_COND_AXIS_NAME_INTERNAL', 'MEAS_COND_AXIS_NAME_MAGICNO', 'MEAS_COND_AXIS_UNIT'];\n",
    "    \n",
    "    for prefix in excluded :\n",
    "        if line.startswith(f'*{prefix}'):\n",
    "            return True;\n",
    "    return False;\n",
    "\n",
    "def readMokeDataFile(file):\n",
    "    data = [];\n",
    "    \n",
    "    for elm in file:\n",
    "        if not (elm.startswith('D') or elm.startswith('P') or elm.startswith('S')):\n",
    "            dataline = [float(number) for number in elm.split()];\n",
    "            if len(dataline) > 0:\n",
    "                data.append(dataline);\n",
    "                \n",
    "    return data;\n",
    "\n",
    "def convertFloat(item):\n",
    "    try:\n",
    "        item = float(item);\n",
    "    except (ValueError, TypeError):\n",
    "        pass;\n",
    "\n",
    "    return item;\n",
    "\n",
    "def writeHDF5_EDX(HDF5_path, filepath, x_pos, y_pos):\n",
    "    ref_dtype = h5py.special_dtype(ref=h5py.Reference);\n",
    "    excluded_base = ['','TRTSpectrum', 'RTHeader', 'ClassInstance', 'TRTHeaderedClass', 'ChildClassInstances', 'TRTKnownHeader',\n",
    "                     'DetectorCount', 'Channels', 'DetLayers', 'PPRTData', 'ReferenceFactor', 'ReferenceFactor2', 'ReferenceStdDev',\n",
    "                     'ResponseFunction', 'ShiftData', 'Result', 'WindowLayers', 'WindowType', 'Type', 'Version', 'Size', 'Atom'];\n",
    "    params = ['Atom','XLine', 'AtomPercent', 'MassPercent', 'NetIntens', 'Background', 'Sigma'];\n",
    "    header_ext = [];\n",
    "    results_ext = [];\n",
    "    spectra_offset = 0;\n",
    "\n",
    "    tree = ET.parse(filepath);\n",
    "    root = tree.getroot();\n",
    "    \n",
    "    for elm in root.iter():\n",
    "        if elm.tag == 'ClassInstance' and elm.get('Name') == 'Results':\n",
    "            for child in elm.iter():\n",
    "                if child.tag == 'Result':\n",
    "                    results_ext.append([]);\n",
    "                elif child.tag in params:\n",
    "                    if child.tag == 'Atom' and int(child.text) < 10:\n",
    "                        results_ext[-1].append((child.tag, f'0{child.text}'));\n",
    "                    else :\n",
    "                        results_ext[-1].append((child.tag, child.text));\n",
    "                elif child.tag == 'ExtResults':\n",
    "                    break;\n",
    "            break;\n",
    "\n",
    "        elif elm.tag not in excluded_base:\n",
    "            header_ext.append((elm.tag, elm.text));\n",
    "        elif elm.tag == 'Channels':\n",
    "            edx_spectra = np.array([(i, int(counts)) for i, counts in enumerate(elm.text.split(','))]);\n",
    "\n",
    "    with h5py.File(HDF5_path, \"a\") as f:\n",
    "        file_group_path = f\"EDX/Spectrum_({x_pos}, {y_pos})\";\n",
    "        spectra = f.create_group(file_group_path);\n",
    "\n",
    "        spectra_data = f.create_group(f\"{file_group_path}/Data\");\n",
    "        spectra_header = f.create_group(f\"{file_group_path}/Header\");\n",
    "        spectra_results = f.create_group(f\"{file_group_path}/Results\");\n",
    "\n",
    "        for elm in header_ext:\n",
    "            header_list = list(spectra_header.keys());#updating the header list each time we add\n",
    "            if elm[1] is not None and elm[0] not in header_list:\n",
    "                elm_1 = convertFloat(elm[1].strip());\n",
    "                hset = spectra_header.create_dataset(f'{elm[0]}', (1,), data=elm_1);\n",
    "\n",
    "        for results in sorted(results_ext):\n",
    "            rgroup_name = f'Atomic Number: {results[0][1]}';\n",
    "            rgroup = spectra_results.create_group(rgroup_name);\n",
    "            for elm in results[1:]:\n",
    "                elm_1 = convertFloat(elm[1].strip());\n",
    "                rset = rgroup.create_dataset(f'{elm[0]}', (1,), data=elm_1);\n",
    "        \n",
    "        dset = spectra_data.create_dataset(\"Counts\", (4096,2), data=edx_spectra);\n",
    "        \n",
    "    return 0;\n",
    "\n",
    "def writeHDF5_XRD(HDF5_path, filename, x_pos, y_pos):\n",
    "    attrib_list = ['SpacegroupNo=', 'HermannMauguin=', 'XrayDensity=', 'Rphase=', 'UNIT=', 'A=', 'B=', 'C=', 'k1=', 'k2=', 'B1='];\n",
    "    header_ext_HW = []; header_ext_MEAS =[];\n",
    "    xrd_pattern = [];\n",
    "    results_XRD = [['R coefficients'], ['Global Parameters'], ['Phases']];\n",
    "    \n",
    "    results_path = filename.replace('.ras','.lst');\n",
    "    current_phase = \"None\";\n",
    "    phs_idx_current = -1;\n",
    "    \n",
    "    with open(filename, 'r', encoding='iso-8859-1') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('*') and not is_excluded(line):\n",
    "                formatted_line = line.strip().split('\\\"')[0:2];\n",
    "                #print(formatted_line)\n",
    "                if line.startswith('*HW'):\n",
    "                    header_ext_HW.append(formatted_line);\n",
    "                elif line.startswith('*MEAS'):\n",
    "                    header_ext_MEAS.append(formatted_line);\n",
    "                else :\n",
    "                    print(f\"[WARNING] Unsupported header attribut \\'{line.split(' ')[0]}\\' => Skipping\")\n",
    "            elif not is_excluded(line):\n",
    "                dataline = [float(elm) for elm in line.split(' ')[0:2]];\n",
    "                xrd_pattern.append(dataline);\n",
    "    xrd_pattern = np.array(xrd_pattern);\n",
    "\n",
    "    with open(results_path, 'r', encoding='iso-8859-1') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('Rp='):\n",
    "                R_factors = line.split();\n",
    "                for elm in [elm.strip().split('=') for elm in R_factors]:\n",
    "                    results_XRD[0].append(elm);\n",
    "            elif line.startswith('Q'):\n",
    "                results_XRD[1].append(line.strip().split('='));\n",
    "            elif line.startswith('Local parameters and GOALs for phase'):\n",
    "                current_phase = line.split()[-1];#name of the current phase for the refined lattice parameters\n",
    "                results_XRD[2].append([current_phase]);\n",
    "                phs_idx_current = results_XRD[2].index([current_phase]);\n",
    "            elif True in [line.startswith(elm) for elm in attrib_list]:\n",
    "                results_XRD[2][phs_idx_current].append(line.strip().split('='));\n",
    "            elif line.startswith('Atomic positions for phase'):\n",
    "                results_XRD[2][phs_idx_current].append(['Atomic positions']);\n",
    "                atomic_pos_idx_current = results_XRD[2][phs_idx_current].index(['Atomic positions']);\n",
    "                next(file);\n",
    "                new_line = file.readline().split();\n",
    "                while len(new_line) > 0:\n",
    "                    results_XRD[2][phs_idx_current][atomic_pos_idx_current].append(new_line);\n",
    "                    #print(results_XRD[2][phs_idx_current][atomic_pos_idx_current]);\n",
    "                    new_line = file.readline().split();\n",
    "\n",
    "    with h5py.File(HDF5_path, \"a\") as f:\n",
    "        file_group_path = f\"XRD/Areamap_({x_pos}, {y_pos})\";\n",
    "        spectra = f.create_group(file_group_path);\n",
    "\n",
    "        spectra_data = f.create_group(f\"{file_group_path}/Data\");\n",
    "        spectra_header = f.create_group(f\"{file_group_path}/Header\");\n",
    "        spectra_results = f.create_group(f\"{file_group_path}/Results\");\n",
    "\n",
    "        spectra_header_hw = spectra_header.create_group(\"Hardware\");\n",
    "        for elm in header_ext_HW:\n",
    "            ##### Patching the weird character values in some attributs ######\n",
    "            attrib = elm[1].split('|');\n",
    "            if len(attrib) > 1:\n",
    "                elm_1 = attrib[1];\n",
    "            else :\n",
    "                elm_1 = attrib[0];\n",
    "            ##################################################################\n",
    "            if elm_1 != '-':\n",
    "                elm_1 = convertFloat(elm_1.strip());\n",
    "                hset_hw = spectra_header_hw.create_dataset(f'{elm[0].replace(\"*HW_\",\"\").strip()}', (1,), data=elm_1);\n",
    "\n",
    "        spectra_header_meas = spectra_header.create_group(\"Measurement\");\n",
    "        for elm in header_ext_MEAS:\n",
    "            if elm[1] != '' and elm[1].strip() != '-':\n",
    "                elm_1 = convertFloat(elm[1].strip());\n",
    "                hset_meas = spectra_header_meas.create_dataset(f'{elm[0].replace(\"*MEAS_\",\"\").strip()}', (1,), data=elm_1);\n",
    "\n",
    "        dset = spectra_data.create_dataset(\"Counts\", (5001,2), data=xrd_pattern);\n",
    "\n",
    "        #print(results_XRD);\n",
    "        for elm in results_XRD:\n",
    "            sub_results = spectra_results.create_group(elm[0]);\n",
    "            for sub_dset in elm[1:]:\n",
    "                if(elm[0] == 'Phases'):\n",
    "                    sub_phase = sub_results.create_group(sub_dset[0]);\n",
    "                    for attrb in sub_dset[1:]:\n",
    "                        if attrb[0] == 'B1':\n",
    "                            attrb[0] = 'W';\n",
    "                        if len(attrb[1:]) > 0:\n",
    "                            sub_phase.create_dataset(f'{attrb[0]}', np.shape(np.array(attrb[1:])), data=[convertFloat(elm) for elm in attrb[1:]]);\n",
    "                else:\n",
    "                    sub_results.create_dataset(f'{sub_dset[0]}', (1,), data=convertFloat(sub_dset[1]));\n",
    "    \n",
    "    return 0;\n",
    "\n",
    "def writeHDF5_MOKE(HDF5_path, MOKE_path, filename, x_pos, y_pos):\n",
    "    header_path = f'{MOKE_path}/info.txt';\n",
    "    header_MOKE = [[\"Sample name\"], [\"Date\"]];\n",
    "    sample_name = (MOKE_path.split('/'))[-1];\n",
    "    result_path = f'./results/MOKE/{sample_name}_MOKE.dat'\n",
    "    data_mag = filename;\n",
    "    data_pul = filename.replace('magnetization','pulse');\n",
    "    data_sum = filename.replace('magnetization','sum');\n",
    "    \n",
    "    data_magnetization = []; data_pulse = []; data_reflectivity = []; results_MOKE = [];\n",
    "\n",
    "    with open(header_path, 'r', encoding='iso-8859-1') as header:\n",
    "        for j, line in enumerate(header):\n",
    "            if j == 0 or j==1:\n",
    "                header_MOKE[j].append(line.split('#')[-1].strip());\n",
    "            else:\n",
    "                header_MOKE.append(line.strip().split('='));\n",
    "    nb_aq = int(header_MOKE[-1][1]);\n",
    "                \n",
    "    with open(\n",
    "        data_mag, 'r', encoding='iso-8859-1') as magnetization, open(\n",
    "        data_pul, 'r', encoding='iso-8859-1') as pulse, open(\n",
    "        data_sum, 'r', encoding='iso-8859-1') as reflectivity:\n",
    "        \n",
    "        data_magnetization = readMokeDataFile(magnetization);\n",
    "        data_pulse = readMokeDataFile(pulse);\n",
    "        data_reflectivity = readMokeDataFile(reflectivity);\n",
    "\n",
    "    with open(result_path, 'r', encoding='iso-8859-1') as file:\n",
    "        results_header = next(file).split('\\t');\n",
    "        for line in file:\n",
    "            line_values = [round(float(elm), 3) for elm in line.split()];\n",
    "            if int(line_values[0]) == x_pos and int(line_values[1]) == y_pos:\n",
    "                results_MOKE = [(results_header[i+2].strip(), elm) for i, elm in enumerate(line_values[2:])];\n",
    "\n",
    "    with h5py.File(HDF5_path, \"a\") as f:\n",
    "        file_group_path = f\"MOKE/Scan_({x_pos}, {y_pos})\";\n",
    "        f.create_group(file_group_path);\n",
    "        \n",
    "        data = f.create_group(f\"{file_group_path}/Data\");\n",
    "        moke_header = f.create_group(f\"{file_group_path}/Header\");\n",
    "        moke_results = f.create_group(f\"{file_group_path}/Results\");\n",
    "\n",
    "        for elm in header_MOKE:\n",
    "            elm_1 = convertFloat(elm[1].strip());\n",
    "            moke_header.create_dataset(elm[0], (1,), data=elm_1);\n",
    "        for elm in results_MOKE:\n",
    "            moke_results.create_dataset(elm[0], (1,), data=elm[1]);\n",
    "\n",
    "        mag_dset = data.create_dataset(\"Magnetization\", (len(data_magnetization),nb_aq), data=data_magnetization);\n",
    "        pul_dset = data.create_dataset(\"Pulse\", (len(data_pulse),nb_aq), data=data_pulse);\n",
    "        sum_dset = data.create_dataset(\"Reflectivity\", (len(data_reflectivity),nb_aq), data=data_reflectivity);\n",
    "\n",
    "    return 0;\n",
    "\n",
    "def main(test=False, tt_x_pos=-30, tt_y_pos=20):\n",
    "    HDF5_path = './NdFeB.hdf5';\n",
    "    EDX_path = './data/EDX/2897_NdFeB';\n",
    "    XRD_path = './data/XRD/2898_NdFeB_600-10s';\n",
    "    MOKE_path = './data/MOKE/NdFeB-sq films/2898-NdFeB-10s600';\n",
    "    \n",
    "    with h5py.File(HDF5_path, \"w\") as f:\n",
    "        f.create_group(\"EDX\");\n",
    "        f.create_group(\"XRD\");\n",
    "        f.create_group(\"MOKE\");\n",
    "    \n",
    "    step_x, step_y = 5, 5;\n",
    "    start_x, start_y = -40, -40;\n",
    "    \n",
    "    for elm in tqdm(sorted(\n",
    "        [datafile for datafile in os.listdir(EDX_path)\n",
    "         if datafile.endswith('.spx')])):\n",
    "    \n",
    "        filepath = f\"{EDX_path}/{elm}\";\n",
    "        x_idx, y_idx = elm.split('.spx')[0].split('(')[-1].split(')')[0].split(',');\n",
    "        x_pos, y_pos = (int(x_idx)-1)*step_x+start_x, (int(y_idx)-1)*step_y+start_y;\n",
    "\n",
    "        if test:\n",
    "            if (x_pos == tt_x_pos and y_pos == tt_y_pos):\n",
    "                writeHDF5_EDX(HDF5_path, filepath, x_pos, y_pos);\n",
    "        elif np.abs(x_pos) + np.abs(y_pos) <= 60 and np.abs(x_pos) <= 40 and np.abs(y_pos) <= 40:\n",
    "            writeHDF5_EDX(HDF5_path, filepath, x_pos, y_pos);\n",
    "\n",
    "    for elm in tqdm(sorted(\n",
    "        [datafile for datafile in os.listdir(XRD_path)\n",
    "         if datafile.startswith('Areamap') and datafile.endswith('.ras')])):\n",
    "        \n",
    "        filepath = f\"{XRD_path}/{elm}\";\n",
    "        indexes = elm.split('.ras')[0].split('_')[-1];\n",
    "        x_idx, y_idx = indexes[0:3], indexes[3:]\n",
    "        x_pos, y_pos = (int(x_idx)-1)*step_x+start_x, (int(y_idx)-1)*step_y+start_y;\n",
    "\n",
    "        if test:\n",
    "            if (x_pos == tt_x_pos and y_pos == tt_y_pos):\n",
    "                writeHDF5_XRD(HDF5_path, filepath, x_pos, y_pos);\n",
    "        elif np.abs(x_pos) + np.abs(y_pos) <= 60 and np.abs(x_pos) <= 40 and np.abs(y_pos) <= 40:\n",
    "            writeHDF5_XRD(HDF5_path, filepath, x_pos, y_pos);\n",
    "\n",
    "    for elm in tqdm(sorted(\n",
    "        [datafile for datafile in os.listdir(MOKE_path)\n",
    "         if datafile.endswith('magnetization.txt')])):\n",
    "\n",
    "        filepath = f\"{MOKE_path}/{elm}\";\n",
    "        indexes = elm.split('_')[1:3];\n",
    "        x_pos, y_pos = int(float(indexes[0].split('x')[-1])), int(float(indexes[1].split('y')[-1]));\n",
    "\n",
    "        if test:\n",
    "            if (x_pos == tt_x_pos and y_pos == tt_y_pos):\n",
    "                writeHDF5_MOKE(HDF5_path, MOKE_path, filepath, x_pos, y_pos);\n",
    "        elif np.abs(x_pos) + np.abs(y_pos) <= 60 and np.abs(x_pos) <= 40 and np.abs(y_pos) <= 40:\n",
    "            writeHDF5_MOKE(HDF5_path, MOKE_path, filepath, x_pos, y_pos);\n",
    "    \n",
    "    with h5py.File(HDF5_path, \"r\") as f:\n",
    "        print(f.keys());\n",
    "        print([len(list(f[key])) for key in f.keys()]);\n",
    "        #print(f['EDX/Spectrum_(10,-5)/Results/Atomic Number: 27'].keys());\n",
    "        #print([elm for elm in f['EDX/Spectrum_(10,-5)/Data/Counts'][()]]);\n",
    "    return 0;\n",
    "\n",
    "#main(True, 20, -15);\n",
    "main();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddc3fbc-21f7-4e89-bf49-1bb99c134c76",
   "metadata": {},
   "source": [
    "**@end-of-notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
